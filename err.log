Current Date And Time Is: 2020-01-23_0413 PM 
Starting...
forrtl: error (200): program aborting due to control-C event
Image              PC                Routine            Line        Source             
libifcoremd.dll    00007FFF84823B58  Unknown               Unknown  Unknown
KERNELBASE.dll     00007FFFE8CB4053  Unknown               Unknown  Unknown
KERNEL32.DLL       00007FFFEB7C7974  Unknown               Unknown  Unknown
ntdll.dll          00007FFFEC24A271  Unknown               Unknown  Unknown
Current Date And Time Is: 2020-01-23_0414 PM 
Starting...
Current Date And Time Is: 2020-01-24_0555 AM 
Starting...
Current Date And Time Is: 2020-01-25_0555 AM 
Starting...
forrtl: error (200): program aborting due to window-CLOSE event
Image              PC                Routine            Line        Source             
libifcoremd.dll    00007FFF54583B58  Unknown               Unknown  Unknown
KERNELBASE.dll     00007FFFE8CB4053  Unknown               Unknown  Unknown
KERNEL32.DLL       00007FFFEB7C7974  Unknown               Unknown  Unknown
ntdll.dll          00007FFFEC24A271  Unknown               Unknown  Unknown
Current Date And Time Is: 2020-01-28_0555 AM 
Starting...
Current Date And Time Is: 2020-01-29_0555 AM 
Starting...
Current Date And Time Is: 2020-01-30_0555 AM 
Starting...
Current Date And Time Is: 2020-01-31_0555 AM 
Starting...
Current Date And Time Is: 2020-02-01_0555 AM 
Starting...
Current Date And Time Is: 2020-02-02_0555 AM 
Starting...
Current Date And Time Is: 2020-02-03_0555 AM 
Starting...
Current Date And Time Is: 2020-02-04_0555 AM 
Starting...
Current Date And Time Is: 2020-02-05_0555 AM 
Starting...
Current Date And Time Is: 2020-02-06_0555 AM 
Starting...
Current Date And Time Is: 2020-02-07_0555 AM 
Starting...
Current Date And Time Is: 2020-02-08_0555 AM 
Starting...
Current Date And Time Is: 2020-02-09_0555 AM 
Starting...
Current Date And Time Is: 2020-02-10_0555 AM 
Starting...
Current Date And Time Is: 2020-02-11_0555 AM 
Starting...
Current Date And Time Is: 2020-02-13_0555 AM 
Starting...
Current Date And Time Is: 2020-02-14_0555 AM 
Starting...
Current Date And Time Is: 2020-02-15_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-16_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-17_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-18_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-20_1016 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-21_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-22_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-23_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-24_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-25_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-26_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-27_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-28_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-02-29_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-01_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-02_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-03_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-04_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-05_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-06_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-07_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-08_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-09_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-10_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-11_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-11_0401 PM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 7, in <module>
    from grib_puller import GRIB_DL
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 10, in <module>
    import panel as pn
ModuleNotFoundError: No module named 'panel'
Current Date And Time Is: 2020-03-12_0555 AM 
Starting...
Current Date And Time Is: 2020-03-13_0555 AM 
Starting...
Current Date And Time Is: 2020-03-14_0555 AM 
Starting...
Current Date And Time Is: 2020-03-15_0555 AM 
Starting...
Current Date And Time Is: 2020-03-16_0555 AM 
Starting...
Current Date And Time Is: 2020-03-17_0555 AM 
Starting...
Current Date And Time Is: 2020-03-18_0719 AM 
Starting...
syntax error, unexpected $end, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: ^
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 29, in main
    create_plot(df, model)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 166, in create_plot
    plt.savefig(os.path.join(imgdir, 'qpf_graph.png'))
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\pyplot.py", line 722, in savefig
    res = fig.savefig(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 2180, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_qt5agg.py", line 88, in print_figure
    super().print_figure(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backend_bases.py", line 2082, in print_figure
    **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 527, in print_png
    FigureCanvasAgg.draw(self)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 388, in draw
    self.figure.draw(self.renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 1709, in draw
    renderer, self, artists, self.suppressComposite)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\axes\_base.py", line 2647, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 621, in draw
    renderer.draw_image(gc, l, b, im)
OverflowError: In draw_image: Exceeded cell block limit
Current Date And Time Is: 2020-03-19_0555 AM 
Starting...
Current Date And Time Is: 2020-03-20_0555 AM 
Starting...
Current Date And Time Is: 2020-03-21_0555 AM 
Starting...
Current Date And Time Is: 2020-03-22_0555 AM 
Starting...
Current Date And Time Is: 2020-03-23_0555 AM 
Starting...
Current Date And Time Is: 2020-03-24_0555 AM 
Starting...
Current Date And Time Is: 2020-03-25_0555 AM 
Starting...
Current Date And Time Is: 2020-03-26_0555 AM 
Starting...
Current Date And Time Is: 2020-03-27_0555 AM 
Starting...
Current Date And Time Is: 2020-03-28_0555 AM 
Starting...
Current Date And Time Is: 2020-03-29_0555 AM 
Starting...
Current Date And Time Is: 2020-03-30_0555 AM 
Starting...
Current Date And Time Is: 2020-04-01_0555 AM 
Starting...
Current Date And Time Is: 2020-04-02_0555 AM 
Starting...
Current Date And Time Is: 2020-04-03_0555 AM 
Starting...
Current Date And Time Is: 2020-04-04_0555 AM 
Starting...
Current Date And Time Is: 2020-04-05_0555 AM 
Starting...
Current Date And Time Is: 2020-04-06_0555 AM 
Starting...
Current Date And Time Is: 2020-04-07_0555 AM 
Starting...
Current Date And Time Is: 2020-04-08_0555 AM 
Starting...
Current Date And Time Is: 2020-04-09_0555 AM 
Starting...
Current Date And Time Is: 2020-04-10_0555 AM 
Starting...
Current Date And Time Is: 2020-04-11_0555 AM 
Starting...
Current Date And Time Is: 2020-04-12_0555 AM 
Starting...
Current Date And Time Is: 2020-04-13_0555 AM 
Starting...
Current Date And Time Is: 2020-04-14_0555 AM 
Starting...
Current Date And Time Is: 2020-04-15_0555 AM 
Starting...
Current Date And Time Is: 2020-04-16_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 51, in model_fz_level
    snow_level = (((hgt_500 - hgt_1000) + tmp_700) * 128) - 64015
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 2588, in func
    self, other = align(self, other, join=align_type, copy=False)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 331, in align
    new_obj = obj.reindex(copy=copy, fill_value=fill_value, **valid_indexers)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 1300, in reindex
    fill_value=fill_value,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2483, in reindex
    **indexers_kwargs,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2514, in _reindex
    sparse=sparse,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 543, in reindex_variables
    "index has duplicate values" % dim
ValueError: cannot reindex or align along dimension 'time' because the index has duplicate values
Current Date And Time Is: 2020-04-17_0555 AM 
Starting...
Current Date And Time Is: 2020-04-18_0555 AM 
Starting...
Current Date And Time Is: 2020-04-19_0555 AM 
Starting...
Current Date And Time Is: 2020-04-20_0555 AM 
Starting...
Current Date And Time Is: 2020-04-21_0555 AM 
Starting...
Current Date And Time Is: 2020-04-22_0637 AM 
Starting...
Current Date And Time Is: 2020-04-23_0555 AM 
Starting...
Current Date And Time Is: 2020-04-24_0555 AM 
Starting...
Current Date And Time Is: 2020-04-25_0555 AM 
Starting...
Current Date And Time Is: 2020-04-26_0555 AM 
Starting...
Current Date And Time Is: 2020-04-27_0555 AM 
Starting...
Current Date And Time Is: 2020-04-28_0555 AM 
Starting...
Current Date And Time Is: 2020-04-29_0555 AM 
Starting...
Current Date And Time Is: 2020-04-30_0555 AM 
Starting...
Current Date And Time Is: 2020-05-01_0555 AM 
Starting...
Current Date And Time Is: 2020-05-02_0555 AM 
Starting...
Current Date And Time Is: 2020-05-03_0555 AM 
Starting...
Current Date And Time Is: 2020-05-04_0555 AM 
Starting...
Current Date And Time Is: 2020-05-05_0555 AM 
Starting...
Current Date And Time Is: 2020-05-06_0555 AM 
Starting...
Current Date And Time Is: 2020-05-07_0555 AM 
Starting...
Current Date And Time Is: 2020-05-08_0555 AM 
Starting...
Current Date And Time Is: 2020-05-09_0555 AM 
Starting...
Current Date And Time Is: 2020-05-10_0555 AM 
Starting...
Current Date And Time Is: 2020-05-11_0555 AM 
Starting...
Current Date And Time Is: 2020-05-12_0555 AM 
Starting...
Current Date And Time Is: 2020-05-13_0640 AM 
Starting...
Current Date And Time Is: 2020-05-14_0555 AM 
Starting...
Current Date And Time Is: 2020-05-15_0555 AM 
Starting...
Current Date And Time Is: 2020-05-16_0555 AM 
Starting...
Current Date And Time Is: 2020-05-17_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 51, in model_fz_level
    snow_level = (((hgt_500 - hgt_1000) + tmp_700) * 128) - 64015
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 2588, in func
    self, other = align(self, other, join=align_type, copy=False)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 331, in align
    new_obj = obj.reindex(copy=copy, fill_value=fill_value, **valid_indexers)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 1300, in reindex
    fill_value=fill_value,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2483, in reindex
    **indexers_kwargs,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2514, in _reindex
    sparse=sparse,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 543, in reindex_variables
    "index has duplicate values" % dim
ValueError: cannot reindex or align along dimension 'time' because the index has duplicate values
Current Date And Time Is: 2020-05-18_0555 AM 
Starting...
Current Date And Time Is: 2020-05-19_0555 AM 
Starting...
Current Date And Time Is: 2020-05-20_0710 AM 
Starting...
Current Date And Time Is: 2020-05-21_0555 AM 
Starting...
Current Date And Time Is: 2020-05-22_0555 AM 
Starting...
Current Date And Time Is: 2020-05-23_0555 AM 
Starting...
Current Date And Time Is: 2020-05-24_0555 AM 
Starting...
Current Date And Time Is: 2020-05-25_0555 AM 
Starting...
Current Date And Time Is: 2020-05-26_0555 AM 
Starting...
Current Date And Time Is: 2020-05-27_0555 AM 
Starting...
Current Date And Time Is: 2020-05-28_0555 AM 
Starting...
Current Date And Time Is: 2020-05-29_0555 AM 
Starting...
Current Date And Time Is: 2020-05-30_0555 AM 
Starting...
Current Date And Time Is: 2020-05-31_0555 AM 
Starting...
Current Date And Time Is: 2020-06-01_0555 AM 
Starting...
Current Date And Time Is: 2020-06-02_0555 AM 
Starting...
Current Date And Time Is: 2020-06-03_0555 AM 
Starting...
Current Date And Time Is: 2020-06-04_0555 AM 
Starting...
Current Date And Time Is: 2020-06-05_0555 AM 
Starting...
Current Date And Time Is: 2020-06-06_0555 AM 
Starting...
Current Date And Time Is: 2020-06-07_0555 AM 
Starting...
Current Date And Time Is: 2020-06-08_0555 AM 
Starting...
Current Date And Time Is: 2020-06-09_0555 AM 
Starting...
Current Date And Time Is: 2020-06-10_0555 AM 
Starting...
Current Date And Time Is: 2020-06-11_0555 AM 
Starting...
Current Date And Time Is: 2020-06-12_0555 AM 
Starting...
Current Date And Time Is: 2020-06-13_0555 AM 
Starting...
Current Date And Time Is: 2020-06-14_0555 AM 
Starting...
Current Date And Time Is: 2020-06-15_0555 AM 
Starting...
Current Date And Time Is: 2020-06-16_0555 AM 
Starting...
Current Date And Time Is: 2020-06-17_0623 AM 
Starting...
Current Date And Time Is: 2020-06-18_0555 AM 
Starting...
Current Date And Time Is: 2020-06-19_0555 AM 
Starting...
Current Date And Time Is: 2020-06-20_0555 AM 
Starting...
Current Date And Time Is: 2020-06-21_0555 AM 
Starting...
Current Date And Time Is: 2020-06-22_0555 AM 
Starting...
Current Date And Time Is: 2020-06-23_0555 AM 
Starting...
Current Date And Time Is: 2020-06-24_0555 AM 
Starting...
Current Date And Time Is: 2020-06-25_0555 AM 
Starting...
Current Date And Time Is: 2020-06-26_0555 AM 
Starting...
Current Date And Time Is: 2020-06-27_0555 AM 
Starting...
Current Date And Time Is: 2020-06-28_0555 AM 
Starting...
Current Date And Time Is: 2020-06-29_0555 AM 
Starting...
Current Date And Time Is: 2020-06-30_0555 AM 
Starting...
Current Date And Time Is: 2020-07-01_0555 AM 
Starting...
Current Date And Time Is: 2020-07-02_0555 AM 
Starting...
Current Date And Time Is: 2020-07-03_0555 AM 
Starting...
Current Date And Time Is: 2020-07-04_0555 AM 
Starting...
Current Date And Time Is: 2020-07-05_0555 AM 
Starting...
Current Date And Time Is: 2020-07-06_0555 AM 
Starting...
Current Date And Time Is: 2020-07-07_0555 AM 
Starting...
Current Date And Time Is: 2020-07-08_0555 AM 
Starting...
Current Date And Time Is: 2020-07-09_0555 AM 
Starting...
Current Date And Time Is: 2020-07-10_0555 AM 
Starting...
Current Date And Time Is: 2020-07-11_0555 AM 
Starting...
Current Date And Time Is: 2020-07-12_0555 AM 
Starting...
Current Date And Time Is: 2020-07-13_0555 AM 
Starting...
Current Date And Time Is: 2020-07-14_0555 AM 
Starting...
Current Date And Time Is: 2020-07-15_0555 AM 
Starting...
Current Date And Time Is: 2020-07-16_0555 AM 
Starting...
Current Date And Time Is: 2020-07-17_0555 AM 
Starting...
Current Date And Time Is: 2020-07-18_0555 AM 
Starting...
Current Date And Time Is: 2020-07-19_0555 AM 
Starting...
Current Date And Time Is: 2020-07-20_0555 AM 
Starting...
Current Date And Time Is: 2020-07-21_0555 AM 
Starting...
Current Date And Time Is: 2020-07-22_0649 AM 
Starting...
Current Date And Time Is: 2020-07-23_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 29, in main
    create_plot(df, model)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 166, in create_plot
    plt.savefig(os.path.join(imgdir, 'qpf_graph.png'))
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\pyplot.py", line 722, in savefig
    res = fig.savefig(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 2180, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_qt5agg.py", line 88, in print_figure
    super().print_figure(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backend_bases.py", line 2082, in print_figure
    **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 527, in print_png
    FigureCanvasAgg.draw(self)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 388, in draw
    self.figure.draw(self.renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 1709, in draw
    renderer, self, artists, self.suppressComposite)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\axes\_base.py", line 2647, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 621, in draw
    renderer.draw_image(gc, l, b, im)
OverflowError: In draw_image: Exceeded cell block limit
Current Date And Time Is: 2020-07-24_0555 AM 
Starting...
Current Date And Time Is: 2020-07-25_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 29, in main
    create_plot(df, model)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 166, in create_plot
    plt.savefig(os.path.join(imgdir, 'qpf_graph.png'))
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\pyplot.py", line 722, in savefig
    res = fig.savefig(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 2180, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_qt5agg.py", line 88, in print_figure
    super().print_figure(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backend_bases.py", line 2082, in print_figure
    **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 527, in print_png
    FigureCanvasAgg.draw(self)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 388, in draw
    self.figure.draw(self.renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 1709, in draw
    renderer, self, artists, self.suppressComposite)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\axes\_base.py", line 2647, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 621, in draw
    renderer.draw_image(gc, l, b, im)
OverflowError: In draw_image: Exceeded cell block limit
Current Date And Time Is: 2020-07-26_0555 AM 
Starting...
Current Date And Time Is: 2020-07-27_0555 AM 
Starting...
Current Date And Time Is: 2020-07-28_0555 AM 
Starting...
Current Date And Time Is: 2020-07-29_0555 AM 
Starting...
Current Date And Time Is: 2020-07-30_0555 AM 
Starting...
Current Date And Time Is: 2020-07-31_0555 AM 
Starting...
Current Date And Time Is: 2020-08-01_0555 AM 
Starting...
Current Date And Time Is: 2020-08-02_0555 AM 
Starting...
Current Date And Time Is: 2020-08-03_0555 AM 
Starting...
Current Date And Time Is: 2020-08-04_0555 AM 
Starting...
Current Date And Time Is: 2020-08-05_0555 AM 
Starting...
Current Date And Time Is: 2020-08-06_0555 AM 
Starting...
Current Date And Time Is: 2020-08-07_0555 AM 
Starting...
Current Date And Time Is: 2020-08-08_0555 AM 
Starting...
Current Date And Time Is: 2020-08-09_0555 AM 
Starting...
Current Date And Time Is: 2020-08-10_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <html^><head><title>Apache Tomcat/6.0.24 - Error report</title><style><!--H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} H3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} BODY {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} B {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} P {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;}A {color : black;}A.name {color : black;}HR {color : #525D76;}--></style> </head><body><h1>HTTP Status 503 - This application is not currently available</h1><HR size="1" noshade="noshade"><p><b>type</b> Status report</p><p><b>message</b> <u>This application is not currently available</u></p><p><b>description</b> <u>The requested service (This application is not currently available) is not currently available.</u></p><HR size="1" noshade="noshade"><h3>Apache Tomcat/6.0.24</h3></body></html>
syntax error, unexpected $end, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: ^
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200810/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 47, in model_fz_level
    hgt_500 = ds.pull_point_data(lat=lat_mf, lon=lon_mf, level=500.0, variable='hgtprs') / 10
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 37, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -77] NetCDF: Access failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200810/gfs_0p25_06z'
Current Date And Time Is: 2020-08-11_0555 AM 
Starting...
Current Date And Time Is: 2020-08-12_0555 AM 
Starting...
Current Date And Time Is: 2020-08-13_0555 AM 
Starting...
Current Date And Time Is: 2020-08-14_0555 AM 
Starting...
Current Date And Time Is: 2020-08-15_0555 AM 
Starting...
Current Date And Time Is: 2020-08-16_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200816/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 47, in model_fz_level
    hgt_500 = ds.pull_point_data(lat=lat_mf, lon=lon_mf, level=500.0, variable='hgtprs') / 10
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 37, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200816/gfs_0p25_06z'
Current Date And Time Is: 2020-08-17_0555 AM 
Starting...
Current Date And Time Is: 2020-08-18_0555 AM 
Starting...
Current Date And Time Is: 2020-08-20_0555 AM 
Starting...
Current Date And Time Is: 2020-08-21_0555 AM 
Starting...
Current Date And Time Is: 2020-08-22_0555 AM 
Starting...
Current Date And Time Is: 2020-08-23_0555 AM 
Starting...
Current Date And Time Is: 2020-08-24_0555 AM 
Starting...
Current Date And Time Is: 2020-08-25_0555 AM 
Starting...
Current Date And Time Is: 2020-08-26_0555 AM 
Starting...
Current Date And Time Is: 2020-08-27_0555 AM 
Starting...
Current Date And Time Is: 2020-08-28_0555 AM 
Starting...
Current Date And Time Is: 2020-08-29_0555 AM 
Starting...
Current Date And Time Is: 2020-08-30_0555 AM 
Starting...
Current Date And Time Is: 2020-08-31_0555 AM 
Starting...
Current Date And Time Is: 2020-09-01_0555 AM 
Starting...
Current Date And Time Is: 2020-09-02_0555 AM 
Starting...
Current Date And Time Is: 2020-09-03_0555 AM 
Starting...
Current Date And Time Is: 2020-09-04_0555 AM 
Starting...
Current Date And Time Is: 2020-09-05_0555 AM 
Starting...
Current Date And Time Is: 2020-09-06_0555 AM 
Starting...
Current Date And Time Is: 2020-09-07_0555 AM 
Starting...
Current Date And Time Is: 2020-09-08_0555 AM 
Starting...
Current Date And Time Is: 2020-09-09_0555 AM 
Starting...
Current Date And Time Is: 2020-09-10_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200910/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 43, in model_fz_level
    qpf = ((ds.pull_point_data(lat=lat_mf, lon=lon_mf, variable='apcpsfc', level='sfc')) * 0.03937)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 37, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20200910/gfs_0p25_06z'
Current Date And Time Is: 2020-09-11_0555 AM 
Starting...
Current Date And Time Is: 2020-09-12_0555 AM 
Starting...
Current Date And Time Is: 2020-09-13_0555 AM 
Starting...
Current Date And Time Is: 2020-09-14_0555 AM 
Starting...
Current Date And Time Is: 2020-09-15_0555 AM 
Starting...
Current Date And Time Is: 2020-09-16_0628 AM 
Starting...
Current Date And Time Is: 2020-09-17_0555 AM 
Starting...
Current Date And Time Is: 2020-09-18_0555 AM 
Starting...
Current Date And Time Is: 2020-09-19_0555 AM 
Starting...
Current Date And Time Is: 2020-09-20_0555 AM 
Starting...
Current Date And Time Is: 2020-09-21_0555 AM 
Starting...
Current Date And Time Is: 2020-09-22_0555 AM 
Starting...
Current Date And Time Is: 2020-09-23_0555 AM 
Starting...
Current Date And Time Is: 2020-09-24_0555 AM 
Starting...
Current Date And Time Is: 2020-09-25_0555 AM 
Starting...
Current Date And Time Is: 2020-09-26_0555 AM 
Starting...
Current Date And Time Is: 2020-09-27_0555 AM 
Starting...
Current Date And Time Is: 2020-09-28_0555 AM 
Starting...
Current Date And Time Is: 2020-09-29_0555 AM 
Starting...
Current Date And Time Is: 2020-09-30_0555 AM 
Starting...
Current Date And Time Is: 2020-10-01_0555 AM 
Starting...
Current Date And Time Is: 2020-10-02_0555 AM 
Starting...
Current Date And Time Is: 2020-10-03_0555 AM 
Starting...
Current Date And Time Is: 2020-10-04_0555 AM 
Starting...
Current Date And Time Is: 2020-10-05_0555 AM 
Starting...
Current Date And Time Is: 2020-10-06_0555 AM 
Starting...
Current Date And Time Is: 2020-10-07_0555 AM 
Starting...
Current Date And Time Is: 2020-10-08_0555 AM 
Starting...
Current Date And Time Is: 2020-10-09_0555 AM 
Starting...
Current Date And Time Is: 2020-10-10_0555 AM 
Starting...
Current Date And Time Is: 2020-10-11_0555 AM 
Starting...
Current Date And Time Is: 2020-10-12_0555 AM 
Starting...
Current Date And Time Is: 2020-10-13_0555 AM 
Starting...
Current Date And Time Is: 2020-10-14_0555 AM 
Starting...
Current Date And Time Is: 2020-10-15_0555 AM 
Starting...
Current Date And Time Is: 2020-10-16_0555 AM 
Starting...
Current Date And Time Is: 2020-10-17_0555 AM 
Starting...
Current Date And Time Is: 2020-10-18_0555 AM 
Starting...
Current Date And Time Is: 2020-10-19_0555 AM 
Starting...
Current Date And Time Is: 2020-10-20_0555 AM 
Starting...
Current Date And Time Is: 2020-10-21_0646 AM 
Starting...
Current Date And Time Is: 2020-10-22_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201022/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201022/gfs_0p25_06z'
Current Date And Time Is: 2020-10-23_0555 AM 
Starting...
Current Date And Time Is: 2020-10-24_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20201024/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20201024/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp02.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201024/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201024/gfs_0p25_06z'
Current Date And Time Is: 2020-10-25_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20201025/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20201025/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp13.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201025/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201025/gfs_0p25_06z'
Current Date And Time Is: 2020-10-26_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20201026/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20201026/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp12.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201026/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201026/gfs_0p25_06z'
Current Date And Time Is: 2020-10-27_0555 AM 
Starting...
Current Date And Time Is: 2020-10-28_0555 AM 
Starting...
Current Date And Time Is: 2020-10-29_0555 AM 
Starting...
Current Date And Time Is: 2020-10-30_0555 AM 
Starting...
Current Date And Time Is: 2020-10-31_0555 AM 
Starting...
Current Date And Time Is: 2020-11-01_0555 AM 
Starting...
Current Date And Time Is: 2020-11-02_0555 AM 
Starting...
Current Date And Time Is: 2020-11-03_0555 AM 
Starting...
Current Date And Time Is: 2020-11-04_0555 AM 
Starting...
Current Date And Time Is: 2020-11-05_0555 AM 
Starting...
Current Date And Time Is: 2020-11-06_0555 AM 
Starting...
Current Date And Time Is: 2020-11-07_0555 AM 
Starting...
Current Date And Time Is: 2020-11-08_0555 AM 
Starting...
Current Date And Time Is: 2020-11-09_0555 AM 
Starting...
Current Date And Time Is: 2020-11-10_0555 AM 
Starting...
Current Date And Time Is: 2020-11-11_0555 AM 
Starting...
Current Date And Time Is: 2020-11-12_0555 AM 
Starting...
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201112/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201112/gfs_0p25_06z'
Current Date And Time Is: 2020-11-13_0555 AM 
Starting...
Current Date And Time Is: 2020-11-14_0555 AM 
Starting...
Current Date And Time Is: 2020-11-15_0555 AM 
Starting...
Current Date And Time Is: 2020-11-16_0555 AM 
Starting...
Current Date And Time Is: 2020-11-17_0555 AM 
Starting...
Current Date And Time Is: 2020-11-18_0703 AM 
Starting...
Current Date And Time Is: 2020-11-19_0555 AM 
Starting...
Current Date And Time Is: 2020-11-20_0555 AM 
Starting...
Current Date And Time Is: 2020-11-21_0555 AM 
Starting...
Current Date And Time Is: 2020-11-22_0555 AM 
Starting...
Current Date And Time Is: 2020-11-23_0555 AM 
Starting...
Current Date And Time Is: 2020-11-24_0555 AM 
Starting...
Current Date And Time Is: 2020-11-25_0555 AM 
Starting...
Current Date And Time Is: 2020-11-26_0555 AM 
Starting...
Current Date And Time Is: 2020-11-27_0555 AM 
Starting...
Current Date And Time Is: 2020-11-28_0555 AM 
Starting...
Current Date And Time Is: 2020-11-29_0555 AM 
Starting...
Current Date And Time Is: 2020-11-30_0555 AM 
Starting...
Current Date And Time Is: 2020-12-01_0555 AM 
Starting...
Current Date And Time Is: 2020-12-02_0555 AM 
Starting...
Current Date And Time Is: 2020-12-03_0555 AM 
Starting...
Current Date And Time Is: 2020-12-04_0555 AM 
Starting...
Current Date And Time Is: 2020-12-05_0555 AM 
Starting...
Current Date And Time Is: 2020-12-06_0555 AM 
Starting...
Current Date And Time Is: 2020-12-07_0555 AM 
Starting...
Current Date And Time Is: 2020-12-08_0555 AM 
Starting...
Current Date And Time Is: 2020-12-09_0555 AM 
Starting...
Current Date And Time Is: 2020-12-10_0555 AM 
Starting...
Current Date And Time Is: 2020-12-11_0555 AM 
Starting...
Current Date And Time Is: 2020-12-12_0555 AM 
Starting...
Current Date And Time Is: 2020-12-13_0555 AM 
Starting...
Current Date And Time Is: 2020-12-14_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201214/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20201214/gfs_0p25_06z'
Current Date And Time Is: 2020-12-15_0555 AM 
Starting...
Current Date And Time Is: 2020-12-16_0555 AM 
Starting...
Current Date And Time Is: 2020-12-17_0555 AM 
Starting...
Current Date And Time Is: 2020-12-18_0555 AM 
Starting...
Current Date And Time Is: 2020-12-19_0555 AM 
Starting...
Current Date And Time Is: 2020-12-20_0555 AM 
Starting...
Current Date And Time Is: 2020-12-21_0555 AM 
Starting...
Current Date And Time Is: 2020-12-22_0555 AM 
Starting...
Current Date And Time Is: 2020-12-23_0555 AM 
Starting...
Current Date And Time Is: 2020-12-24_0555 AM 
Starting...
Current Date And Time Is: 2020-12-25_0555 AM 
Starting...
Current Date And Time Is: 2020-12-26_0555 AM 
Starting...
Current Date And Time Is: 2020-12-27_0555 AM 
Starting...
Current Date And Time Is: 2020-12-28_0555 AM 
Starting...
Current Date And Time Is: 2020-12-29_0555 AM 
Starting...
Current Date And Time Is: 2020-12-30_0555 AM 
Starting...
Current Date And Time Is: 2020-12-31_0555 AM 
Starting...
Current Date And Time Is: 2021-01-01_0555 AM 
Starting...
Current Date And Time Is: 2021-01-02_0555 AM 
Starting...
Current Date And Time Is: 2021-01-03_0555 AM 
Starting...
Current Date And Time Is: 2021-01-04_0555 AM 
Starting...
Current Date And Time Is: 2021-01-05_0555 AM 
Starting...
Current Date And Time Is: 2021-01-06_0555 AM 
Starting...
Current Date And Time Is: 2021-01-07_0555 AM 
Starting...
Current Date And Time Is: 2021-01-08_0555 AM 
Starting...
Current Date And Time Is: 2021-01-09_0555 AM 
Starting...
Current Date And Time Is: 2021-01-10_0555 AM 
Starting...
Current Date And Time Is: 2021-01-11_0555 AM 
Starting...
Current Date And Time Is: 2021-01-12_0555 AM 
Starting...
Current Date And Time Is: 2021-01-13_0555 AM 
Starting...
Current Date And Time Is: 2021-01-14_0555 AM 
Starting...
Current Date And Time Is: 2021-01-15_0555 AM 
Starting...
Current Date And Time Is: 2021-01-16_0555 AM 
Starting...
Current Date And Time Is: 2021-01-17_0555 AM 
Starting...
Current Date And Time Is: 2021-01-18_0555 AM 
Starting...
Current Date And Time Is: 2021-01-19_0555 AM 
Starting...
Current Date And Time Is: 2021-01-20_0555 AM 
Starting...
Current Date And Time Is: 2021-01-21_0555 AM 
Starting...
Current Date And Time Is: 2021-01-22_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210122/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210122/gfs_0p25_06z'
Current Date And Time Is: 2021-01-23_0555 AM 
Starting...
Current Date And Time Is: 2021-01-24_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <html^><head><title>Apache Tomcat/6.0.24 - Error report</title><style><!--H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} H3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} BODY {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} B {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} P {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;}A {color : black;}A.name {color : black;}HR {color : #525D76;}--></style> </head><body><h1>HTTP Status 404 - /dods/gfs_0p25/gfs20210124/gfs_0p25_06z.das</h1><HR size="1" noshade="noshade"><p><b>type</b> Status report</p><p><b>message</b> <u>/dods/gfs_0p25/gfs20210124/gfs_0p25_06z.das</u></p><p><b>description</b> <u>The requested resource (/dods/gfs_0p25/gfs20210124/gfs_0p25_06z.das) is not available.</u></p><HR size="1" noshade="noshade"><h3>Apache Tomcat/6.0.24</h3></body></html>
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 29, in main
    create_plot(df, model)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 166, in create_plot
    plt.savefig(os.path.join(imgdir, 'qpf_graph.png'))
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\pyplot.py", line 722, in savefig
    res = fig.savefig(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 2180, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_qt5agg.py", line 88, in print_figure
    super().print_figure(*args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backend_bases.py", line 2082, in print_figure
    **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 527, in print_png
    FigureCanvasAgg.draw(self)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\backends\backend_agg.py", line 388, in draw
    self.figure.draw(self.renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\figure.py", line 1709, in draw
    renderer, self, artists, self.suppressComposite)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\axes\_base.py", line 2647, in draw
    mimage._draw_list_compositing_images(renderer, self, artists)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 135, in _draw_list_compositing_images
    a.draw(renderer)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\artist.py", line 38, in draw_wrapper
    return draw(artist, renderer, *args, **kwargs)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\matplotlib\image.py", line 621, in draw
    renderer.draw_image(gc, l, b, im)
OverflowError: In draw_image: Exceeded cell block limit
Current Date And Time Is: 2021-01-25_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20210125/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20210125/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp13.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210125/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 36, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 31, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210125/gfs_0p25_06z'
Current Date And Time Is: 2021-01-26_0555 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20210126/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20210126/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp12.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210126/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 291, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 28, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 46, in model_fz_level
    hgt_1000 = ds.pull_point_data(lat=lat_mf, lon=lon_mf, level=1000.0, variable='hgtprs') / 10
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 37, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210126/gfs_0p25_06z'
Current Date And Time Is: 2021-01-27_0555 AM 
Starting...
Current Date And Time Is: 2021-01-28_0555 AM 
Starting...
Current Date And Time Is: 2021-01-29_0555 AM 
Starting...
Current Date And Time Is: 2021-01-30_0555 AM 
Starting...
Current Date And Time Is: 2021-01-31_0555 AM 
Starting...
Current Date And Time Is: 2021-02-01_0555 AM 
Starting...
Current Date And Time Is: 2021-02-02_0555 AM 
Starting...
Current Date And Time Is: 2021-02-03_0555 AM 
Starting...
Current Date And Time Is: 2021-02-04_0555 AM 
Starting...
Current Date And Time Is: 2021-02-05_0555 AM 
Starting...
Current Date And Time Is: 2021-02-06_0555 AM 
Starting...
Current Date And Time Is: 2021-02-07_0555 AM 
Starting...
Current Date And Time Is: 2021-02-08_0555 AM 
Starting...
Current Date And Time Is: 2021-02-09_0555 AM 
Starting...
Current Date And Time Is: 2021-02-10_0555 AM 
Starting...
Current Date And Time Is: 2021-02-11_0555 AM 
Starting...
Current Date And Time Is: 2021-02-12_0555 AM 
Starting...
Current Date And Time Is: 2021-02-13_0555 AM 
Starting...
Current Date And Time Is: 2021-02-14_0555 AM 
Starting...
Current Date And Time Is: 2021-02-15_0555 AM 
Starting...
Current Date And Time Is: 2021-02-16_0555 AM 
Starting...
Current Date And Time Is: 2021-02-17_0555 AM 
Starting...
Current Date And Time Is: 2021-02-18_0555 AM 
Starting...
Current Date And Time Is: 2021-02-19_0555 AM 
Starting...
Current Date And Time Is: 2021-02-20_0555 AM 
Starting...
Current Date And Time Is: 2021-02-21_0555 AM 
Starting...
Current Date And Time Is: 2021-02-22_0555 AM 
Starting...
Current Date And Time Is: 2021-02-22_1128 AM 
Starting...
Python was not found but can be installed from the Microsoft Store: ms-windows-store://pdp/?productid=9NJ46SX7X90PCurrent Date And Time Is: 2021-02-22_1129 AM 
Starting...
syntax error, unexpected WORD_WORD, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: <!DOCTYPE^ HTML PUBLIC "-//IETF//DTD HTML 2.0//EN"><html><head><title>502 Proxy Error</title></head><body><h1>Proxy Error</h1><p>The proxy server received an invalidresponse from an upstream server.<br />The proxy server could not handle the request <em><a href="/dods/gfs_0p25/gfs20210222/gfs_0p25_06z.dds">GET&nbsp;/dods/gfs_0p25/gfs20210222/gfs_0p25_06z.dds</a></em>.<p>Reason: <strong>DNS lookup failure for: vm-bldr-idpapp10.ncep.noaa.gov</strong></p></p></body></html>
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210222/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 292, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 29, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 41, in model_fz_level
    sd = (ds.pull_point_data(lat=lat_mf, lon=lon_mf, variable='snodsfc', level='sfc')) * 39.37
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 33, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210222/gfs_0p25_06z'
Current Date And Time Is: 2021-02-23_0555 AM 
Starting...
Current Date And Time Is: 2021-02-24_1023 AM 
Starting...
Python was not found but can be installed from the Microsoft Store: ms-windows-store://pdp/?productid=9NJ46SX7X90PCurrent Date And Time Is: 2021-02-24_1044 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 57, in model_fz_level
    df = pd.concat([df_qpf, df_sd, df_snowlevel], axis=1)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\reshape\concat.py", line 255, in concat
    sort=sort,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\reshape\concat.py", line 428, in __init__
    self.new_axes = self._get_new_axes()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\reshape\concat.py", line 497, in _get_new_axes
    new_axes[i] = self._get_comb_axis(i)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\reshape\concat.py", line 529, in _get_comb_axis
    self.objs, axis=data_axis, intersect=self.intersect, sort=self.sort
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\api.py", line 93, in _get_objs_combined_axis
    return _get_combined_index(obs_idxes, intersect=intersect, sort=sort)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\api.py", line 140, in _get_combined_index
    index = _union_indexes(indexes, sort=sort)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\api.py", line 203, in _union_indexes
    return result.union_many(indexes[1:])
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\datetimes.py", line 554, in union_many
    this = Index.union(this, other)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\base.py", line 2519, in union
    return self._union(other, sort=sort)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\datetimes.py", line 520, in _union
    result = Index._union(this, other, sort=sort)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\base.py", line 2568, in _union
    indexer = self.get_indexer(other)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\pandas\core\indexes\base.py", line 2985, in get_indexer
    "Reindexing only valid with uniquely" " valued Index objects"
pandas.core.indexes.base.InvalidIndexError: Reindexing only valid with uniquely valued Index objects
Current Date And Time Is: 2021-02-25_0555 AM 
Starting...
Current Date And Time Is: 2021-02-26_0555 AM 
Starting...
Current Date And Time Is: 2021-02-27_0555 AM 
Starting...
Current Date And Time Is: 2021-02-28_0555 AM 
Starting...
Current Date And Time Is: 2021-03-01_0555 AM 
Starting...
Current Date And Time Is: 2021-03-02_0555 AM 
Starting...
Current Date And Time Is: 2021-03-03_0555 AM 
Starting...
Current Date And Time Is: 2021-03-04_0555 AM 
Starting...
Current Date And Time Is: 2021-03-05_0555 AM 
Starting...
Current Date And Time Is: 2021-03-06_0555 AM 
Starting...
Current Date And Time Is: 2021-03-07_0555 AM 
Starting...
Current Date And Time Is: 2021-03-08_0555 AM 
Starting...
Current Date And Time Is: 2021-03-09_0555 AM 
Starting...
Current Date And Time Is: 2021-03-10_0555 AM 
Starting...
Current Date And Time Is: 2021-03-11_0555 AM 
Starting...
Current Date And Time Is: 2021-03-12_0555 AM 
Starting...
Current Date And Time Is: 2021-03-13_0555 AM 
Starting...
Current Date And Time Is: 2021-03-14_0555 AM 
Starting...
Current Date And Time Is: 2021-03-15_0555 AM 
Starting...
Current Date And Time Is: 2021-03-16_0555 AM 
Starting...
Current Date And Time Is: 2021-03-17_0555 AM 
Starting...
Current Date And Time Is: 2021-03-18_0555 AM 
Starting...
Current Date And Time Is: 2021-03-19_0555 AM 
Starting...
Current Date And Time Is: 2021-03-20_0555 AM 
Starting...
Current Date And Time Is: 2021-03-21_0555 AM 
Starting...
Current Date And Time Is: 2021-03-22_0555 AM 
Starting...
Current Date And Time Is: 2021-03-23_0555 AM 
Starting...
Current Date And Time Is: 2021-03-24_0555 AM 
Starting...
Current Date And Time Is: 2021-03-25_0555 AM 
Starting...
Current Date And Time Is: 2021-03-26_0555 AM 
Starting...
Current Date And Time Is: 2021-03-27_0555 AM 
Starting...
Current Date And Time Is: 2021-03-28_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210328/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 50, in model_fz_level
    hgt_500 = ds.pull_point_data(lat=lat_mf, lon=lon_mf, level=500.0, variable='hgtprs') / 10
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 33, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210328/gfs_0p25_06z'
Current Date And Time Is: 2021-03-29_0555 AM 
Starting...
Current Date And Time Is: 2021-03-30_0555 AM 
Starting...
Current Date And Time Is: 2021-03-31_0555 AM 
Starting...
Current Date And Time Is: 2021-04-01_0555 AM 
Starting...
Current Date And Time Is: 2021-04-02_0555 AM 
Starting...
Current Date And Time Is: 2021-04-03_0555 AM 
Starting...
Current Date And Time Is: 2021-04-04_0555 AM 
Starting...
Current Date And Time Is: 2021-04-05_0555 AM 
Starting...
Current Date And Time Is: 2021-04-06_0555 AM 
Starting...
Current Date And Time Is: 2021-04-07_0555 AM 
Starting...
Current Date And Time Is: 2021-04-08_0555 AM 
Starting...
Current Date And Time Is: 2021-04-09_0555 AM 
Starting...
Current Date And Time Is: 2021-04-10_0555 AM 
Starting...
Current Date And Time Is: 2021-04-11_0555 AM 
Starting...
Current Date And Time Is: 2021-04-12_0555 AM 
Starting...
Current Date And Time Is: 2021-04-13_0555 AM 
Starting...
Current Date And Time Is: 2021-04-14_0555 AM 
Starting...
Current Date And Time Is: 2021-04-15_0555 AM 
Starting...
Current Date And Time Is: 2021-04-16_0555 AM 
Starting...
Current Date And Time Is: 2021-04-17_0555 AM 
Starting...
Current Date And Time Is: 2021-04-18_0555 AM 
Starting...
Current Date And Time Is: 2021-04-19_0555 AM 
Starting...
Current Date And Time Is: 2021-04-20_0555 AM 
Starting...
Current Date And Time Is: 2021-04-21_0555 AM 
Starting...
Current Date And Time Is: 2021-04-22_0555 AM 
Starting...
Current Date And Time Is: 2021-04-23_0555 AM 
Starting...
Current Date And Time Is: 2021-04-24_0555 AM 
Starting...
Current Date And Time Is: 2021-04-25_0555 AM 
Starting...
Current Date And Time Is: 2021-04-26_0555 AM 
Starting...
Current Date And Time Is: 2021-04-27_0555 AM 
Starting...
Current Date And Time Is: 2021-04-28_0555 AM 
Starting...
Current Date And Time Is: 2021-04-29_0555 AM 
Starting...
Current Date And Time Is: 2021-04-30_0555 AM 
Starting...
Current Date And Time Is: 2021-05-01_0555 AM 
Starting...
Current Date And Time Is: 2021-05-02_0555 AM 
Starting...
Current Date And Time Is: 2021-05-03_0555 AM 
Starting...
Current Date And Time Is: 2021-05-04_0555 AM 
Starting...
Current Date And Time Is: 2021-05-06_0555 AM 
Starting...
Current Date And Time Is: 2021-05-07_0555 AM 
Starting...
Current Date And Time Is: 2021-05-08_0555 AM 
Starting...
Current Date And Time Is: 2021-05-09_0555 AM 
Starting...
Current Date And Time Is: 2021-05-10_0555 AM 
Starting...
Current Date And Time Is: 2021-05-11_0555 AM 
Starting...
Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 54, in model_fz_level
    snow_level = (((hgt_500 - hgt_1000) + tmp_700) * 128) - 64015
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 2588, in func
    self, other = align(self, other, join=align_type, copy=False)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 331, in align
    new_obj = obj.reindex(copy=copy, fill_value=fill_value, **valid_indexers)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataarray.py", line 1300, in reindex
    fill_value=fill_value,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2483, in reindex
    **indexers_kwargs,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\dataset.py", line 2514, in _reindex
    sparse=sparse,
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\core\alignment.py", line 543, in reindex_variables
    "index has duplicate values" % dim
ValueError: cannot reindex or align along dimension 'time' because the index has duplicate values
Current Date And Time Is: 2021-05-13_0555 AM 
Starting...
Current Date And Time Is: 2021-05-14_0555 AM 
Starting...
syntax error, unexpected $end, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: ^
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210514/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 46, in model_fz_level
    qpf = ((ds.pull_point_data(lat=lat_mf, lon=lon_mf, variable='apcpsfc', level='sfc')) * 0.03937)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 33, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -77] NetCDF: Access failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210514/gfs_0p25_06z'
Current Date And Time Is: 2021-05-15_0555 AM 
Starting...
Current Date And Time Is: 2021-05-16_0555 AM 
Starting...
Current Date And Time Is: 2021-05-17_0555 AM 
Starting...
Current Date And Time Is: 2021-05-18_0555 AM 
Starting...
Current Date And Time Is: 2021-05-20_0555 AM 
Starting...
Current Date And Time Is: 2021-05-21_0555 AM 
Starting...
Current Date And Time Is: 2021-05-22_0555 AM 
Starting...
Current Date And Time Is: 2021-05-23_0555 AM 
Starting...
Current Date And Time Is: 2021-05-24_0555 AM 
Starting...
Current Date And Time Is: 2021-05-25_0555 AM 
Starting...
syntax error, unexpected $end, expecting SCAN_ATTR or SCAN_DATASET or SCAN_ERROR
context: ^
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210525/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 46, in model_fz_level
    qpf = ((ds.pull_point_data(lat=lat_mf, lon=lon_mf, variable='apcpsfc', level='sfc')) * 0.03937)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 33, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -77] NetCDF: Access failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210525/gfs_0p25_06z'
Current Date And Time Is: 2021-05-26_0555 AM 
Starting...
Current Date And Time Is: 2021-05-28_0555 AM 
Starting...
Current Date And Time Is: 2021-05-29_0555 AM 
Starting...
Current Date And Time Is: 2021-05-30_0555 AM 
Starting...
Current Date And Time Is: 2021-05-31_0555 AM 
Starting...
Current Date And Time Is: 2021-06-01_0555 AM 
Starting...
Current Date And Time Is: 2021-06-03_0555 AM 
Starting...
Current Date And Time Is: 2021-06-04_0555 AM 
Starting...
Current Date And Time Is: 2021-06-05_0555 AM 
Starting...
Current Date And Time Is: 2021-06-06_0555 AM 
Starting...
Current Date And Time Is: 2021-06-07_0555 AM 
Starting...
Current Date And Time Is: 2021-06-08_0555 AM 
Starting...
Current Date And Time Is: 2021-06-09_0555 AM 
Starting...
Current Date And Time Is: 2021-06-10_0555 AM 
Starting...
Current Date And Time Is: 2021-06-11_0555 AM 
Starting...
Current Date And Time Is: 2021-06-12_0555 AM 
Starting...
Current Date And Time Is: 2021-06-13_0555 AM 
Starting...
Current Date And Time Is: 2021-06-14_0555 AM 
Starting...
Current Date And Time Is: 2021-06-15_0555 AM 
Starting...
Current Date And Time Is: 2021-06-16_0645 AM 
Starting...
Current Date And Time Is: 2021-06-17_0555 AM 
Starting...
Current Date And Time Is: 2021-06-18_0555 AM 
Starting...
Current Date And Time Is: 2021-06-19_0555 AM 
Starting...
Current Date And Time Is: 2021-06-20_0555 AM 
Starting...
Current Date And Time Is: 2021-06-21_0555 AM 
Starting...
Current Date And Time Is: 2021-06-22_0555 AM 
Starting...
Current Date And Time Is: 2021-06-23_0555 AM 
Starting...
Current Date And Time Is: 2021-06-24_0555 AM 
Starting...
Current Date And Time Is: 2021-06-25_0555 AM 
Starting...
Current Date And Time Is: 2021-06-26_0555 AM 
Starting...
Current Date And Time Is: 2021-06-27_0555 AM 
Starting...
Current Date And Time Is: 2021-06-28_0555 AM 
Starting...
Current Date And Time Is: 2021-06-29_0555 AM 
Starting...
Current Date And Time Is: 2021-06-30_0555 AM 
Starting...
Current Date And Time Is: 2021-07-01_0555 AM 
Starting...
Current Date And Time Is: 2021-07-02_0555 AM 
Starting...
Current Date And Time Is: 2021-07-03_0555 AM 
Starting...
Current Date And Time Is: 2021-07-04_0555 AM 
Starting...
Current Date And Time Is: 2021-07-05_0555 AM 
Starting...
Current Date And Time Is: 2021-07-06_0555 AM 
Starting...
Current Date And Time Is: 2021-07-07_0555 AM 
Starting...
Current Date And Time Is: 2021-07-08_0555 AM 
Starting...
Current Date And Time Is: 2021-07-09_0555 AM 
Starting...
Current Date And Time Is: 2021-07-10_0555 AM 
Starting...
Current Date And Time Is: 2021-07-11_0555 AM 
Starting...
Current Date And Time Is: 2021-07-12_0555 AM 
Starting...
Current Date And Time Is: 2021-07-13_0555 AM 
Starting...
Current Date And Time Is: 2021-07-15_0555 AM 
Starting...
Current Date And Time Is: 2021-07-16_0555 AM 
Starting...
Current Date And Time Is: 2021-07-17_0555 AM 
Starting...
Current Date And Time Is: 2021-07-18_0555 AM 
Starting...
Current Date And Time Is: 2021-07-19_0555 AM 
Starting...
Current Date And Time Is: 2021-07-20_0555 AM 
Starting...
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210720/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 43, in model_fz_level
    sd = (ds.pull_point_data(lat=lat_mf, lon=lon_mf, variable='snodsfc', level='sfc')) * 39.37
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 33, in pull_point_data
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210720/gfs_0p25_06z'
Current Date And Time Is: 2021-07-22_0555 AM 
Starting...
Current Date And Time Is: 2021-07-23_0555 AM 
Starting...
Current Date And Time Is: 2021-07-24_0555 AM 
Starting...
Current Date And Time Is: 2021-07-25_0555 AM 
Starting...
Current Date And Time Is: 2021-07-26_0555 AM 
Starting...
Current Date And Time Is: 2021-07-27_0555 AM 
Starting...
Current Date And Time Is: 2021-07-28_0555 AM 
Starting...
Current Date And Time Is: 2021-07-29_0555 AM 
Starting...
Current Date And Time Is: 2021-07-30_0555 AM 
Starting...
Current Date And Time Is: 2021-07-31_0555 AM 
Starting...
Current Date And Time Is: 2021-08-01_0555 AM 
Starting...
Current Date And Time Is: 2021-08-02_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210802/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 39, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 23, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210802/gfs_0p25_06z'
Current Date And Time Is: 2021-08-03_0555 AM 
Starting...
Current Date And Time Is: 2021-08-04_0555 AM 
Starting...
Current Date And Time Is: 2021-08-05_0555 AM 
Starting...
Current Date And Time Is: 2021-08-06_0555 AM 
Starting...
Current Date And Time Is: 2021-08-07_0555 AM 
Starting...
Current Date And Time Is: 2021-08-08_0555 AM 
Starting...
Current Date And Time Is: 2021-08-09_0555 AM 
Starting...
Current Date And Time Is: 2021-08-10_0555 AM 
Starting...
Current Date And Time Is: 2021-08-11_0555 AM 
Starting...
Current Date And Time Is: 2021-08-12_0555 AM 
Starting...
Current Date And Time Is: 2021-08-13_0555 AM 
Starting...
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210813/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 39, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 23, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -70] NetCDF: DAP server error: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210813/gfs_0p25_06z'
Current Date And Time Is: 2021-08-14_0555 AM 
Starting...
Current Date And Time Is: 2021-08-15_0555 AM 
Starting...
Current Date And Time Is: 2021-08-16_0555 AM 
Starting...
Current Date And Time Is: 2021-08-17_0555 AM 
Starting...
Current Date And Time Is: 2021-08-19_0555 AM 
Starting...
Current Date And Time Is: 2021-08-20_0555 AM 
Starting...
Current Date And Time Is: 2021-08-21_0555 AM 
Starting...
Current Date And Time Is: 2021-08-22_0555 AM 
Starting...
Current Date And Time Is: 2021-08-23_0555 AM 
Starting...
Current Date And Time Is: 2021-08-24_0555 AM 
Starting...
Current Date And Time Is: 2021-08-25_0555 AM 
Starting...
Current Date And Time Is: 2021-08-27_0555 AM 
Starting...
curl error details: 
Traceback (most recent call last):
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 198, in _acquire_with_cache_info
    file = self._cache[self._key]
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\lru_cache.py", line 53, in __getitem__
    value = self._cache[key]
KeyError: [<class 'netCDF4._netCDF4.Dataset'>, ('https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210827/gfs_0p25_06z',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 294, in <module>
    main()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 31, in main
    df = model_fz_level(model, lat_mf, lon_mf, today)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\snow_level_plotter.py", line 39, in model_fz_level
    ds = GRIB_DL(model=model, model_resolution=model_res, date=date)
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 23, in __init__
    self.vtimes = self.valid_times()
  File "U:\Documents\Programming\PycharmProjects\Prod\SnowLevel_Bot\grib_puller.py", line 27, in valid_times
    ds = xr.open_dataset(self.url)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\api.py", line 502, in open_dataset
    filename_or_obj, group=group, lock=lock, **backend_kwargs
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 358, in open
    return cls(manager, group=group, mode=mode, lock=lock, autoclose=autoclose)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 314, in __init__
    self.format = self.ds.data_model
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 367, in ds
    return self._acquire()
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\netCDF4_.py", line 361, in _acquire
    with self._manager.acquire_context(needs_lock) as root:
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\contextlib.py", line 112, in __enter__
    return next(self.gen)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 186, in acquire_context
    file, cached = self._acquire_with_cache_info(needs_lock)
  File "C:\Users\smotley\AppData\Local\Continuum\anaconda3\envs\Data_Grabber\lib\site-packages\xarray\backends\file_manager.py", line 204, in _acquire_with_cache_info
    file = self._opener(*self._args, **kwargs)
  File "netCDF4\_netCDF4.pyx", line 2321, in netCDF4._netCDF4.Dataset.__init__
  File "netCDF4\_netCDF4.pyx", line 1885, in netCDF4._netCDF4._ensure_nc_success
OSError: [Errno -68] NetCDF: I/O failure: b'https://nomads.ncep.noaa.gov/dods/gfs_0p25/gfs20210827/gfs_0p25_06z'
Current Date And Time Is: 2021-08-28_0555 AM 
Starting...
Current Date And Time Is: 2021-08-29_0555 AM 
Starting...
Current Date And Time Is: 2021-08-30_0555 AM 
Starting...
Current Date And Time Is: 2021-08-31_0555 AM 
Starting...
Current Date And Time Is: 2021-09-01_0555 AM 
Starting...
Current Date And Time Is: 2021-09-02_0555 AM 
Starting...
Current Date And Time Is: 2021-09-03_0555 AM 
Starting...
Current Date And Time Is: 2021-09-04_0555 AM 
Starting...
Current Date And Time Is: 2021-09-05_0555 AM 
Starting...
Current Date And Time Is: 2021-09-06_0555 AM 
Starting...
Current Date And Time Is: 2021-09-07_0555 AM 
Starting...
Current Date And Time Is: 2021-09-08_0555 AM 
Starting...
Current Date And Time Is: 2021-09-09_0555 AM 
Starting...
Current Date And Time Is: 2021-09-10_0555 AM 
Starting...
Current Date And Time Is: 2021-09-11_0555 AM 
Starting...
Current Date And Time Is: 2021-09-12_0555 AM 
Starting...
Current Date And Time Is: 2021-09-13_0555 AM 
Starting...
Current Date And Time Is: 2021-09-14_0555 AM 
Starting...
Current Date And Time Is: 2021-09-15_0555 AM 
Starting...
Current Date And Time Is: 2021-09-16_0555 AM 
Starting...
